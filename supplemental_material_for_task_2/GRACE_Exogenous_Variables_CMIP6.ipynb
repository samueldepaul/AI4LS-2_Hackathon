{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae11a6e-ea3b-446c-b9ac-ea61d418fb7a",
   "metadata": {},
   "source": [
    "# CMIP6 Exogenous Variables for GRACE 5y forecast (Climate Models MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d196a4c-a0b3-4582-b8d5-befeae7d0925",
   "metadata": {},
   "source": [
    "This script processes local NetCDF files containing climate data by clipping them to basin geometries, calculating the average value within each basin, and, if necessary, finding the nearest grid point. The resulting time series for each basin is saved as a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab299960-c409-4c59-b2b3-72a3368abf6c",
   "metadata": {},
   "source": [
    "#### Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fd2c675-a0dd-4919-aedc-e18ece275c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Libraries for working with multidimensional arrays\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# More libraries\n",
    "import xarray as xr\n",
    "import dask\n",
    "import gc\n",
    "import os\n",
    "import rioxarray\n",
    "from shapely import wkt\n",
    "from scipy.spatial import cKDTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a4573c1-6ca5-47f2-80ed-fb536507cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction to show all rows and columns when printing dataframes \n",
    "pd.set_option(\"display.max_columns\", None) \n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d10f3-1562-43f7-9d7c-4d145725a2f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the directory containing local NetCDF files\n",
    "data_directory = 'CMIP6_downloads'\n",
    "\n",
    "# Function to find the nearest point on the lat/lon grid to a given basin geometry\n",
    "def find_nearest(lat, lon, basin_geom):\n",
    "    \"\"\"\n",
    "    Find the nearest point on the lat/lon grid to the centroid of a basin geometry.\n",
    "    \"\"\"\n",
    "    latlon_points = [(lt, ln) for lt in lat for ln in lon]  # Create a list of lat/lon point pairs\n",
    "    tree = cKDTree(latlon_points)  # Use a KDTree for efficient nearest-neighbor search\n",
    "    basin_center = basin_geom.centroid  # Get the centroid of the basin\n",
    "    dist, idx = tree.query([basin_center.y, basin_center.x])  # Find the nearest point in the grid\n",
    "    nearest_point = latlon_points[idx]\n",
    "    return nearest_point\n",
    "\n",
    "# Function to process a local NetCDF file for a specific climate variable\n",
    "def process_local_nc_file(filepath, gdf):\n",
    "    \"\"\"\n",
    "    Processes a local NetCDF file, extracts climate data, and clips it to basin geometries.\n",
    "    \n",
    "    Parameters:\n",
    "    - filepath (str): Path to the NetCDF file.\n",
    "    - gdf (GeoDataFrame): GeoDataFrame with basin geometries.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Basin time series data with corresponding year and month.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load the dataset from the NetCDF file\n",
    "    exog_var = xr.open_dataset(filepath)\n",
    "    \n",
    "    # 2. Select the last variable available in the dataset\n",
    "    last_variable = list(exog_var.data_vars.keys())[-1]\n",
    "    exog_var = exog_var[[last_variable]]\n",
    "    print(f\"Processing variable '{last_variable}' from {filepath}\")\n",
    "\n",
    "    # 3. Filter the dataset for dates after January 2015\n",
    "    exog_var = exog_var.sel(time=slice(\"2015-01-01\", None))\n",
    "    \n",
    "    # 4. Ensure the dataset has the correct CRS and apply chunking for latitude, longitude, and time\n",
    "    exog_var = exog_var.rio.write_crs(\"EPSG:4326\")\n",
    "    exog_var = exog_var.chunk({'lat': 50, 'lon': 50, 'time': 50})\n",
    "\n",
    "    # 5. Initialize a list to store Dask tasks for parallel processing\n",
    "    tasks = []\n",
    "    \n",
    "    # 6. Function to process each basin and clip the exog_var dataset\n",
    "    @dask.delayed\n",
    "    def process_basin(geom, basin_id):\n",
    "        # Check if the grid points fall within the basin\n",
    "        mask = exog_var.rio.clip([geom], exog_var.rio.crs, drop=False)\n",
    "        \n",
    "        if mask[last_variable].notnull().any():\n",
    "            # If grid points exist within the basin, average the values\n",
    "            basin_series = mask[last_variable].mean(dim=['lat', 'lon']).compute()\n",
    "        else:\n",
    "            # If no points exist, find the nearest grid point to the basin\n",
    "            nearest_lat, nearest_lon = find_nearest(exog_var['lat'].values, exog_var['lon'].values, geom)\n",
    "            nearest_point = exog_var.sel(lat=nearest_lat, lon=nearest_lon)\n",
    "            basin_series = nearest_point[last_variable].compute()\n",
    "        \n",
    "        return pd.Series(basin_series.values, name=basin_id)\n",
    "    \n",
    "    # 7. Loop through the basin geometries and apply the processing function\n",
    "    for _, row in gdf.iterrows():\n",
    "        task = process_basin(row['geometry'], row['basin_id'])  # Create the delayed task\n",
    "        tasks.append(task)  # Add the task to the list\n",
    "    \n",
    "    # 8. Compute all tasks in parallel using Dask\n",
    "    basin_time_series = dask.compute(*tasks)\n",
    "    \n",
    "    # 9. Create a DataFrame from the basin time series\n",
    "    basin_time_series_df = pd.concat(basin_time_series, axis=1)\n",
    "    basin_time_series_df['datetime'] = pd.to_datetime(exog_var['time'].values)  # Convert time to datetime\n",
    "    \n",
    "    # Extract year and month from the datetime column\n",
    "    basin_time_series_df['Year'] = basin_time_series_df['datetime'].dt.year\n",
    "    basin_time_series_df['Month'] = basin_time_series_df['datetime'].dt.month\n",
    "\n",
    "    return basin_time_series_df\n",
    "\n",
    "# Main function to process all NetCDF files in the directory\n",
    "def process_all_files(gdf):\n",
    "    \"\"\"\n",
    "    Processes all NetCDF files in the specified directory, extracting and aggregating \n",
    "    time series data for each basin.\n",
    "    \n",
    "    Parameters:\n",
    "    - gdf (GeoDataFrame): GeoDataFrame with basin geometries.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Combined time series data for all basins.\n",
    "    \"\"\"\n",
    "    all_basin_series = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(data_directory):\n",
    "        if filename.endswith(\".nc\"):\n",
    "            filepath = os.path.join(data_directory, filename)\n",
    "            basin_series_df = process_local_nc_file(filepath, gdf)\n",
    "            all_basin_series = pd.concat([all_basin_series, basin_series_df], axis=1)\n",
    "    \n",
    "    # Clean up memory\n",
    "    gc.collect()\n",
    "    \n",
    "    return all_basin_series\n",
    "\n",
    "# Load basin information from a CSV file and convert it to a GeoDataFrame\n",
    "gdf = gpd.read_file('basin_info_df.csv')\n",
    "gdf['geometry'] = gdf['geometry'].apply(wkt.loads)  # Load WKT geometries\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "gdf.set_crs(\"EPSG:4326\", inplace=True)  # Set CRS if not defined\n",
    "\n",
    "# Process all NetCDF files in the local directory\n",
    "basin_time_series = process_all_files(gdf)\n",
    "\n",
    "# Save the processed time series data to a CSV file\n",
    "basin_time_series.to_csv('processed_basin_time_series.csv', index=False)\n",
    "\n",
    "print(\"Process completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb7ac51-0d94-4046-9971-f19e1e596763",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataframe is already saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
